**Step 1: Data Acquisition, Loading & Understanding**


# Import the necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

# Load the file into a Pandas DataFrame.
try:
    df = pd.read_csv('supply_chain_data.csv')
except FileNotFoundError:
    print("The file 'supply_chain_data.csv' was not found. Please ensure the file is in the correct directory.")
# Display the first 5 rows to verify
df.head()

# display the last 5 rows to verify
df.tail()
# Dimensions of dataset
df.shape
     
# Column names
df.columns
# Dataset summary information
df.info()
The dataset has only Nine(9) categorical features and the remaining are Numerical.
**Step 2: Data Cleaning and Preprocessing**
Things to do:

>Check for missing values, duplicates, and incorrect data types.

>Convert numerical columns that are stored as objects/strings into a float or integer format.

>Standardize text data in categorical columns.
Handle any inconsistencies.

# Check for missing values and data types
missing_values = df.isnull().sum()
print("Missing Values:\n", missing_values)
There are no Missing Values

# Standardize categorical data (e.g., 'haircare ' -> 'haircare')
df['Product type'] = df['Product type'].str.strip()
df['Shipping carriers'] = df['Shipping carriers'].str.strip()

# check for duplicates
duplicates = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicates}")
We have no Duplicates in the data
# Verify the changes
print(df.describe())
df.info()
#CHECK AND HANDLE OUTLIERS

# List of columns to check for outliers
columns_to_check = [
   'Price', 'Revenue generated', 'Shipping costs', 'Manufacturing costs', 'Defect rates', 'Costs'
]

# Dictionary to store outliers for each column
outliers_data = {}

for column in columns_to_check:
    # Check if the column exists in the DataFrame
    if column in df.columns:
        # Calculate Q1 (25th percentile) and Q3 (75th percentile)
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        
        # Define the outlier boundaries
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # Find the outliers
        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
        
        # Store the outliers in the dictionary
        if not outliers.empty:
            outliers_data[column] = outliers
            print(f"Outliers found in '{column}':\n")
            print(outliers)
            print("-" * 50)
        else:
            print(f"No outliers found in '{column}'.")
            print("-" * 50)
    else:
        print(f"Column '{column}' not found in the DataFrame.")
        print("-" * 50)
**Step 3: Feature Engineering**

**Action**:
> 1. Calculate Profit for each product.

> 2. Calculate Profit Margin to understand profitability as a percentage.

> 3. Categorize Lead times and Shipping times into bins (e.g., 'Fast', 'Medium', 'Slow') to simplify analysis.

# Calculate 'Profit' by subtracting 'Manufacturing costs' and 'Shipping costs' from 'Revenue generated'
df['Profit'] = df['Revenue generated'] - df['Manufacturing costs'] - df['Shipping costs']

# Display the new 'Profit' column and its descriptive statistics
print("DataFrame with new 'Profit' column:")
print(df[['Revenue generated', 'Manufacturing costs', 'Shipping costs', 'Profit']].head())
print("\nDescriptive statistics for 'Profit':")
print(df['Profit'].describe())
print(df[['Revenue generated', 'Manufacturing costs', 'Shipping costs', 'Profit']].head())
# Convert relevant columns to numeric type
cols_to_convert = ['Price', 'Revenue generated', 'Shipping costs', 'Manufacturing costs', 'Defect rates', 'Costs']
for col in cols_to_convert:
    # Use to_numeric with errors='coerce' to turn non-convertible values into NaN
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Drop any rows that couldn't be converted (if any)
df.dropna(subset=cols_to_convert, inplace=True)

df.head()
# Create bins for lead and shipping times
df['Lead time category'] = pd.cut(df['Lead times'], bins=[0, 10, 20, 30], labels=['Fast (0-10 days)', 'Medium (11-20 days)', 'Slow (21-30 days)'])
df['Shipping time category'] = pd.cut(df['Shipping times'], bins=[0, 3, 7, 10], labels=['Fast (0-3 days)', 'Medium (4-7 days)', 'Slow (8-10 days)'])

# Display the new features
print(df[['Revenue generated', 'Costs', 'Profit', 'Lead time category', 'Shipping time category']].head())

**Step 4: Exploratory Data Analysis (EDA) with Python**

**Action**:
> **1. Financial Performance**:

>>>Calculate total revenue and profit by product type.

>>>Identify the top 5 most profitable products.

> **2. Operational Efficiency**:

>>>Compare average lead times and costs across different suppliers.

>>>Analyze shipping performance by carrier.

>>>Correlate stock levels with sales.

> **3. Quality and Risk**:

>>>Calculate defect rates by product type and supplier.

>>>Analyze inspection results.

# Set a style for the plots
sns.set_style("whitegrid")

# Summary statistics
df.describe().T
# 1. Financial Performance
print("\n--- Financial Performance ---")
product_revenue = df.groupby('Product type')['Revenue generated'].sum().sort_values(ascending=False)
product_profit = df.groupby('Product type')['Profit'].sum().sort_values(ascending=False)
print("Total Revenue by Product Type:\n", product_revenue)
print("\nTotal Profit by Product Type:\n", product_profit)

# Visualize revenue by product type
plt.figure(figsize=(10, 6))
sns.barplot(x=product_revenue.index, y=product_revenue.values, palette="viridis")
plt.title('Total Revenue by Product Type')
plt.xlabel('Product Type')
plt.ylabel('Total Revenue')
plt.show()

**Skincare** is the clear leader in your product portfolio, generating the highest total revenue and profit. While haircare and cosmetics also perform well, they lag behind skincare in overall financial contribution.

**Detailed Breakdown**

>**Skincare is the Top Performer**:

>>>It generated the most revenue, with a total of $241,628.16.

>>>It also produced the highest profit, totaling $219,398.84.

>>>This indicates a high demand and strong sales performance for skincare products.

>**Haircare is a Strong Second**:

>>>Haircare is your second most valuable product type, with $174,455.39 in revenue.

>>>It generated a solid profit of $157,126.53, reinforcing its position as a significant contributor to the business.

>**Cosmetics are a Key Contributor**:

>>>Cosmetics generated $161,521.27 in revenue, placing it just behind haircare.

>>>Its profit of $148,154.87 is also very strong.

>>>Notably, cosmetics show a slightly higher profit margin on a percentage basis, suggesting they are a highly efficient product line.

**Key Takeaway**
The data shows a clear hierarchy of performance, with skincare at the top, followed by haircare and cosmetics. To maximize revenue and profit, the business should continue to focus its efforts on the skincare category, while also identifying opportunities to grow the haircare and cosmetics lines.
# 2. Operational Efficiency
print("\n--- Operational Efficiency ---")
supplier_performance = df.groupby('Supplier name').agg(
    Avg_Lead_Time=('Lead times', 'mean'),
    Avg_Shipping_Cost=('Shipping costs', 'mean'),
    Total_Costs=('Costs', 'sum')
).sort_values(by='Avg_Lead_Time')
print("Supplier Performance:\n", supplier_performance)

# Visualize average lead time by supplier
plt.figure(figsize=(10, 6))
sns.barplot(x=supplier_performance.index, y=supplier_performance['Avg_Lead_Time'], palette="mako")
plt.title('Average Lead Time by Supplier')
plt.xlabel('Supplier Name')
plt.ylabel('Average Lead Time (days)')
plt.show()

Supplier 3 is your most efficient and cost-effective supplier, with the fastest average lead times and the lowest average shipping costs. In contrast, Supplier 4 has the longest lead times, while Supplier 1 has the highest overall total costs.

**Detailed Breakdown**
> 1. **Lead Time Performance (Speed)**:

>>>**Best**: Supplier 3 is the most efficient with an average lead time of just 14.33 days.

>>>**Worst**: Supplier 4 has the longest average lead time at 17.00 days, which could indicate potential bottlenecks or inefficiencies in their process.

> 2. **Shipping Cost Performance (Cost-Effectiveness)**:

>>>**Lowest Cost**: Supplier 3 is also the most cost-effective, with an average shipping cost of $4.79.

>>>**Highest Cost**: Supplier 5 has the highest average shipping cost at $5.79, but all other suppliers are in a similar range.

>3. **Total Costs (Overall Spend)**:

>>> Supplier 1 accounts for the highest total costs at $15,520.98. This could be due to a higher volume of business with this supplier or a combination of their higher lead times and shipping costs.

>>>Supplier 3 has the lowest total costs at $7,032.00, further solidifying its position as a top-tier partner.

**Key Takeaway**
Supplier 3 is a high-performing partner that excels in both speed and cost. We should consider relying more heavily on this supplier if possible.

Conversely, the performance of Supplier 4 and Supplier 1 warrants further investigation. We may need to look into the specific products they supply, their quality metrics, or their pricing to understand if the longer lead times and higher costs are justified.
# 3. Quality and Risk
print("\n--- Quality and Risk ---")
inspection_results = df['Inspection results'].value_counts()
print("Inspection Results:\n", inspection_results)
defect_rate_by_supplier = df.groupby('Supplier name')['Defect rates'].mean().sort_values(ascending=False)
print("\nAverage Defect Rate by Supplier:\n", defect_rate_by_supplier)

# Visualize inspection results
plt.figure(figsize=(8, 8))
plt.pie(inspection_results, labels=inspection_results.index, autopct='%1.1f%%', colors=sns.color_palette('pastel'))
plt.title('Distribution of Inspection Results')
plt.show()

Based on the Results above, the ***quality control process appears to have significant issues**. The high number of Failed and Pending inspections suggests major quality assurance and operational bottlenecks. While the average defect rates across all suppliers are relatively low, Supplier 5 is a potential risk as they have the highest average defect rate.

**Detailed Breakdown**
>**Inspection Results (Overall Quality Control)**:

>>>>**High Failure Rate**: The number of failed inspections (36) is a major cause for concern. This indicates that a large portion of incoming goods do not meet your quality standards.

>>>>**Significant Backlog**: The highest count is for Pending inspections (41). This suggests a bottleneck in your quality control process, which could be delaying inventory and impacting delivery times.

>>>>**Low Pass Rate**: The number of successful inspections (Pass) is the lowest (23), highlighting a pervasive quality issue with your incoming shipments.

>**Average Defect Rate by Supplier**:

>>>>**Highest Risk**: Supplier 5 has the highest average defect rate at 2.67%. Although this seems like a small number, it suggests a higher probability of receiving faulty products from this supplier compared to others.

>>>>**Lowest Risk**: Supplier 1 has the lowest average defect rate at 1.80%, making them the most reliable supplier in terms of product quality.

**Key Takeaway**
There is need to immediately address the quality control process. The high volume of failed and pending inspections is a critical operational problem that could lead to customer dissatisfaction and increased costs. A thorough investigation of the products and suppliers associated with these failed inspections is necessary to prevent future issues. It is also recommended to monitor Supplier 5 more closely.
# 4. Stock vs. Sales & Revenue (Scatter Plots)
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Stock levels', y='Number of products sold', data=df)
plt.title('Number of Products Sold vs. Stock Levels')
plt.xlabel('Stock Levels')
plt.ylabel('Number of Products Sold')
plt.savefig('plot_stock_vs_sales.png')
plt.show()
The chart shows no clear correlation between stock levels (x-axis) and products sold (y-axis), with data points widely scattered.

**Key Points**:

>>**No Correlation**: Stock levels do not directly affect sales.

>>**Data Range**: Stock varies from 0 to 100; sales range from 0 to nearly 1000.

>>**Sales Variability**: High (80-100) and low (0-20) stock levels show inconsistent sales.

>>**Max Sales**: Highest sales (950-1000) occur at various stock levels.

**Conclusion**:

Sales are influenced by factors beyond stock levels, such as demand, marketing, and external conditions. Adjusting inventory alone may not effectively boost sales.
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Availability', y='Revenue generated', data=df)
plt.title('Revenue Generated vs. Availability')
plt.xlabel('Availability')
plt.ylabel('Revenue Generated ($)')
plt.savefig('plot_availability_vs_revenue.png')
plt.show()
The scatter plot "Revenue Generated vs. Availability" illustrates the relationship between product availability (x-axis) and revenue (y-axis).

**Key Observations**:

>>**No Correlation**: Availability does not clearly impact revenue; high stock doesn't ensure high sales.

>>**Data Range**: Availability varies from 0 to 100; revenue ranges from under $1,000 to nearly $10,000.

>>**High Revenue with Low Availability**: Significant revenue can occur with low stock (0-20).

>>**Low Revenue with High Availability**: Many high stock levels (80-100) show low revenue (under $2,000).

>>**Variable Outcomes**: Revenue is inconsistent across availability levels.

**Conclusion**:

Availability is not the main driver of revenue. Other influencing factors include:

>>**Product Price**: High-priced items can generate more revenue at low availability.

>>**Demand**: Popular products sell out quickly.

>>**Marketing Efforts**: Effective campaigns boost sales regardless of stock.

>>**Seasonal Promotions**: Revenue may spike during specific events.

Companies should focus on these factors.
# 5. Manufacturing Costs & Production vs. Defect Rates (Scatter Plots)
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Manufacturing costs', y='Defect rates', data=df)
plt.title('Defect Rates vs. Manufacturing Costs')
plt.xlabel('Manufacturing Costs ($)')
plt.ylabel('Defect Rates (%)')
plt.savefig('plot_manuf_costs_vs_defects.png')
plt.show()
The scatter plot shows an inverse relationship between manufacturing costs and defect rates, with significant variability in the data points. Higher manufacturing costs generally correspond to lower defect rates, but some outliers exist.
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Production volumes', y='Defect rates', data=df)
plt.title('Defect Rates vs. Production Volumes')
plt.xlabel('Production Volumes')
plt.ylabel('Defect Rates (%)')
plt.savefig('plot_prod_volumes_vs_defects.png')
plt.show()

print("\nAll plots generated and saved.")
The Image above shows the relationship between defect rates and production volumes. There is an inverse trend, where higher production volumes generally correspond to lower defect rates, but significant variability is also observed.

# Create a contingency table to show the relationship between CustomerSegment and Product type
# This will show the count of each product type bought by each customer segment
customer_product_cross = pd.crosstab(df['Customer demographics'], df['Product type'])
print("Count of Products by Customer Demographics and Product Type:\\n", customer_product_cross)

# Normalize the crosstab to get percentages, which makes it easier to compare segments
customer_product_percentage = customer_product_cross.div(customer_product_cross.sum(axis=1), axis=0) * 100
print("\\nPercentage of Products by Customer Demographics and Product Type:\\n", customer_product_percentage)

# Visualize the relationship using a stacked bar chart
customer_product_percentage.plot(kind='bar', stacked=True, figsize=(12, 8))
plt.title('Product Type Distribution by Customer Demographics')
plt.xlabel('Customer Demographics')
plt.ylabel('Percentage of Purchases')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Product Type', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.savefig('plot_customer_demographics_vs_products.png')
plt.show()

#LinearRegression

# X is the independent variable (Shipping costs), y is the dependent variable (Revenue generated)
# We reshape X to a 2D array as required by scikit-learn
X = df['Shipping costs'].values.reshape(-1, 1)
y = df['Revenue generated'].values

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Get the R-squared value to evaluate the model's fit
r_squared = model.score(X, y)

print(f"Model Intercept: {model.intercept_}")
print(f"Model Coefficient (for 'Shipping costs'): {model.coef_[0]}")
print(f"R-squared value: {r_squared:.4f}")
print("\nInterpretation: The R-squared value indicates how well the model explains the variability of 'Revenue generated'.")
**REGRESSION ANALYSIS**



# Step 1: Handle categorical variables using one-hot encoding
# This converts the 'Product type' column into numerical dummy variables
df_encoded = pd.get_dummies(df, columns=['Product type'], drop_first=True)

# Step 2: Dynamically identify all product type columns
# This approach makes the code more robust and less prone to errors
product_type_cols = [col for col in df_encoded.columns if col.startswith('Product type_')]

# Step 3: Define your independent (X) and dependent (y) variables
# We include 'Shipping costs', 'Lead times', 'Stock levels', and all new product type columns
features = ['Shipping costs', 'Lead times', 'Stock levels'] + product_type_cols
X = df_encoded[features]
y = df_encoded['Revenue generated']

# Step 4: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Create and fit the multiple linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 6: Make predictions on the test set and calculate the R-squared value
y_pred = model.predict(X_test)
r2 = r2_score(y_test, y_pred)

print("Multiple Regression Model Results:")
print(f"Model Intercept: {model.intercept_}")
print(f"Model Coefficients:")
for feature, coef in zip(X.columns, model.coef_):
    print(f" - {feature}: {coef:.4f}")
print(f"\nR-squared value: {r2:.4f}")
### **1. R-squared Value**

The **R-squared value** is **0.1192**, which means that approximately **11.92%** of the variability in 'Revenue generated' can be explained by the combination of 'Shipping costs', 'Lead times', 'Stock levels', and 'Product type'.It also indicates that other unmodeled factors still account for a large portion of the revenue variation.

---

### **2. Model Intercept**

The **Model Intercept** ($6871.29) represents the predicted baseline revenue when all other variables in the model are zero. For example, if 'Shipping costs', 'Lead times', and 'Stock levels' were all zero and the product type was the baseline category (in this case, 'cosmetics', as it was the category `get_dummies` dropped), the model predicts a revenue of approximately $6871.

---

### **3. Model Coefficients**

The coefficients show the predicted impact of each variable on revenue, assuming all other variables are held constant.

* **Shipping costs** ($19.55): For every dollar increase in 'Shipping costs', 'Revenue generated' is predicted to increase by about $19.55. This might seem counterintuitive, but in a multiple regression, this can indicate that higher shipping costs are correlated with higher-value orders. For example, customers might be paying more for shipping for larger or more expensive products.

* **Lead times** (-$8.04): For every one-day increase in 'Lead times', 'Revenue generated' is predicted to decrease by approximately $8.04. This makes logical sense, as longer delivery times can lead to customer dissatisfaction and a drop in sales.

* **Stock levels** (-$11.28): For every one-unit increase in 'Stock levels', 'Revenue generated' is predicted to decrease by approximately $11.28. This suggests that products with higher stock levels may be less popular or have lower demand, leading to a negative impact on overall revenue.

* **Product type_haircare** (-$1124.63) and **Product type_skincare** (-$384.64): These are coefficients for the dummy variables. They are interpreted relative to the baseline category ('cosmetics').
    * **Haircare**: A product of type 'haircare' is predicted to generate approximately $1,124 less revenue than a product of type 'cosmetics', holding all other factors constant.
    * **Skincare**: A product of type 'skincare' is predicted to generate approximately $385 less revenue than a 'cosmetics' product, holding all other factors constant.

In summary, this model confirms that **'Lead times'** have a negative impact on revenue, while higher **'Shipping costs'** are associated with higher revenue. The **'Product type'** also has a significant impact, with 'cosmetics' showing a higher relative revenue compared to 'haircare' and 'skincare' products in this model.


# Save the DataFrame to a new CSV file Using index=False
df.to_csv('supply_chain_data_cleaned.csv', index=False)

print("Your cleaned and engineered data has been saved to 'supply_chain_data_cleaned.csv'")
